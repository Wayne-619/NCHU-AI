{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4KuMpn75Iz8b",
        "outputId": "4bf8e93f-bee4-4be8-d616-6103191bab8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Alessandro Parisi\n",
            "\n",
            "Last updated: 2022-11-06\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.7.15\n",
            "IPython version      : 7.9.0\n",
            "\n",
            "numpy     : 1.21.6\n",
            "pandas    : 1.3.5\n",
            "matplotlib: 3.2.2\n",
            "sklearn   : 1.0.2\n",
            "seaborn   : 0.11.2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%load_ext watermark\n",
        "%watermark -a \"Alessandro Parisi\" -u -d -v -p numpy,pandas,matplotlib,sklearn,seaborn\n",
        "# to install watermark launch 'pip install watermark' at command line"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install watermark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grMvik01I5fi",
        "outputId": "76aecd0a-a96c-4ceb-dea0-a8f13581e698"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: watermark in /usr/local/lib/python3.7/dist-packages (2.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from watermark) (4.13.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from watermark) (7.9.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->watermark) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->watermark) (4.1.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (2.0.10)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (0.18.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (0.7.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->watermark) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->watermark) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->watermark) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->watermark) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJqjThv9Czot",
        "outputId": "c156872d-89d1-443e-9c25-279b9fe2290e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "rvlWc9SWIz8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3576883-c37b-48f7-b50b-551cb8671cdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from textblob import TextBlob\n",
        "import pandas\n",
        "import sklearn\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "nltk.download('popular')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "from defs import get_tokens\n",
        "from defs import get_lemmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "F7WOQULiIz8e"
      },
      "outputs": [],
      "source": [
        "sms = pandas.read_csv('/content/drive/MyDrive/中興大學- 人工智慧與資訊安全/sms_spam_svm.csv', sep=',', names=[\"type\", \"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "AVpZ5pjMIz8e"
      },
      "outputs": [],
      "source": [
        "text_train, text_test, type_train, type_test = train_test_split(sms['text'], sms['type'], test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "yuIvl5AfIz8f"
      },
      "outputs": [],
      "source": [
        "bow = CountVectorizer(analyzer=get_lemmas).fit(text_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "oXwjQ_qPIz8f"
      },
      "outputs": [],
      "source": [
        "sms_bow = bow.transform(text_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "KOWhRyJsIz8g"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfTransformer().fit(sms_bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "Z51YbZUAIz8g"
      },
      "outputs": [],
      "source": [
        "sms_tfidf = tfidf.transform(sms_bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "yb1aEI-fIz8h"
      },
      "outputs": [],
      "source": [
        "spam_detector = MultinomialNB().fit(sms_tfidf, type_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "utGcCOMAIz8h",
        "outputId": "c62b422d-9d30-4ead-c0c1-aad72a91a7a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted: 0\n",
            "expected: 48\n"
          ]
        }
      ],
      "source": [
        "msg = sms['text'][25]\n",
        "msg_bow = bow.transform([msg])\n",
        "msg_tfidf = tfidf.transform(msg_bow)\n",
        "\n",
        "print ('predicted:', spam_detector.predict(msg_tfidf)[0])\n",
        "print ('expected:', sms.type[25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "-PVBSoHNIz8i"
      },
      "outputs": [],
      "source": [
        "predictions = spam_detector.predict(sms_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "D6LMuWbBIz8i",
        "outputId": "5ccbf93d-8b38-45b9-9670-730569f48d67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.06666666666666667\n"
          ]
        }
      ],
      "source": [
        "print ('accuracy', accuracy_score(sms['type'][:len(predictions)], predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-vbGOW3gIz8j",
        "outputId": "ac28a25d-d996-431e-bc4d-c948d59179c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.13      0.35      0.19        17\n",
            "           1       0.00      0.00      0.00         9\n",
            "           2       0.00      0.00      0.00         4\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00         7\n",
            "          43       0.00      0.00      0.00         1\n",
            "          44       0.00      0.00      0.00         3\n",
            "          46       0.00      0.00      0.00         4\n",
            "          47       0.00      0.00      0.00         2\n",
            "          48       0.00      0.00      0.00         5\n",
            "          49       0.00      0.00      0.00         5\n",
            "           6       0.03      0.17      0.05         6\n",
            "          60       0.00      0.00      0.00         4\n",
            "          61       0.00      0.00      0.00         4\n",
            "          62       0.00      0.00      0.00         2\n",
            "          63       0.00      0.00      0.00         5\n",
            "          64       0.00      0.00      0.00         2\n",
            "          66       0.00      0.00      0.00         2\n",
            "          67       0.00      0.00      0.00         3\n",
            "          68       0.00      0.00      0.00         1\n",
            "          69       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         7\n",
            "          70       0.00      0.00      0.00         1\n",
            "          71       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         5\n",
            "           9       0.00      0.00      0.00         2\n",
            "     suspect       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.07       105\n",
            "   macro avg       0.01      0.02      0.01       105\n",
            "weighted avg       0.02      0.07      0.03       105\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print (classification_report(sms['type'][:len(predictions)], predictions))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Py35",
      "language": "python",
      "name": "py35"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}